# ğŸš€ AI DBAgent - AI-Powered Database Management Tool

> **AI-based Database Monitoring, Analysis and Automation Platform for SRE/DBA**

**AI DBAgent is a modern database management tool that enables natural language database queries, real-time AWS CloudWatch metrics monitoring, and streamlined database operations through automated playbooks.**

<div style="color: #666; margin-top: 10px;">

> **SRE/DBAìš© AI ê¸°ë°˜ ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë‹ˆí„°ë§, ë¶„ì„ ë° ìë™í™” í”Œë«í¼**

AI DBAgentëŠ” ìì—°ì–´ë¡œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¡°íšŒí•˜ê³ , AWS CloudWatch ë©”íŠ¸ë¦­ì„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§í•˜ë©°, ìë™í™”ëœ í”Œë ˆì´ë¶ì„ í†µí•´ ë°ì´í„°ë² ì´ìŠ¤ ìš´ì˜ì„ íš¨ìœ¨í™”í•˜ëŠ” í˜„ëŒ€ì ì¸ DB ê´€ë¦¬ ë„êµ¬ì…ë‹ˆë‹¤.

</div>

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone repository
git clone <repository-url>
cd AI_DBAgent

# Automatic development environment setup
./scripts/dev-setup.sh
```

<div style="color: #666;">

### 1. í™˜ê²½ ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd AI_DBAgent

# ê°œë°œ í™˜ê²½ ì„¤ì • (ìë™)
./scripts/dev-setup.sh
```

</div>

### 2. Environment Variables Configuration

Create a `.env` file and add the following content:

```env
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_USER=dbagentuser
DB_PASSWORD=supersecret
DB_NAME=dbagent

# AWS Configuration (Optional)
AWS_DEFAULT_REGION=ap-northeast-2

# Application Configuration
SECRET_KEY=supersecretkey123
DEBUG=true
```

<div style="color: #666;">

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •![alt text](image.png)

`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:

```env
# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
DB_HOST=localhost
DB_PORT=5432
DB_USER=dbagentuser
DB_PASSWORD=supersecret
DB_NAME=dbagent

# AWS ì„¤ì • (ì„ íƒì‚¬í•­)
AWS_DEFAULT_REGION=ap-northeast-2

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
SECRET_KEY=supersecretkey123
DEBUG=true
```

</div>

### 3. Running the Application

#### Development Environment (Recommended)
```bash
# Start development server (Backend + Frontend)
./scripts/start-dev.sh
```

#### Manual Execution
```bash
# Run Backend
pip install -r requirements.txt
uvicorn main:app --reload

# Run Frontend (New Terminal)
cd frontend
npm install
npm start
```

#### Docker Compose Execution
```bash
# Run entire stack with Docker Compose
docker-compose up -d
```

<div style="color: #666;">

### 3. ì‹¤í–‰ ë°©ë²•

#### ê°œë°œ í™˜ê²½ (ê¶Œì¥)
```bash
# ê°œë°œ ì„œë²„ ì‹œì‘ (ë°±ì—”ë“œ + í”„ë¡ íŠ¸ì—”ë“œ)
./scripts/start-dev.sh
```

#### ìˆ˜ë™ ì‹¤í–‰
```bash
# ë°±ì—”ë“œ ì‹¤í–‰
pip install -r requirements.txt
uvicorn main:app --reload

# í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰ (ìƒˆ í„°ë¯¸ë„)
cd frontend
npm install
npm start
```

#### Docker ì‹¤í–‰
```bash
# Docker Composeë¡œ ì „ì²´ ìŠ¤íƒ ì‹¤í–‰
docker-compose up -d
```

</div>

### 4. Access URLs

- **WEB**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs

<div style="color: #666;">

### 4. ì ‘ì†

- **WEB**: http://localhost:8000
- **API ë¬¸ì„œ**: http://localhost:8000/docs

</div>

## âœ¨ Key Features

### ğŸ¤– AI-Powered Natural Language SQL Translation
- **Multi-AI Model Support**: OpenAI, Azure OpenAI, Google Gemini, Anthropic Claude
- **Multi-Language Interface**: Full Korean/English support with language toggle button
- **Interactive Interface**: Natural Q&A through chat-based interface
- **Query Execution & Interpretation**: Automatic SQL execution and result analysis
- **Conversation History**: Database-specific conversation history management

### ğŸ”— MCP (Model Context Protocol) Integration
- **Automatic Database Registration**: Auto-setup MCP servers when registering databases
- **Real-time Synchronization**: Automatic sync between registered databases and MCP servers
- **PostgreSQL MCP Server**: Dedicated MCP server creation for each database
- **AI Chat Integration**: Automatic inclusion of MCP context in AI conversations
- **Status Monitoring**: Real-time MCP integration status monitoring and management

### ğŸ“‹ Automated Playbooks
- **Pre-defined Scenarios**: GDPR compliance, daily health checks, weekly reviews, etc.
- **Auto-execution Mode**: Step-by-step automatic progression (3-second intervals)
- **Manual Execution Mode**: Step-by-step manual control
- **Real-time Progress**: Live playbook execution status display
- **Chat Integration**: View playbook results in chat interface

### ğŸ“Š Real-time Monitoring
- **AWS CloudWatch Integration**: Real-time RDS/Aurora metrics collection
- **Key Metrics Monitoring**: CPU, Memory, Connections, IOPS, Storage, etc.
- **Visualization**: Intuitive dashboard with cards and graphs
- **Auto-detection**: Automatic instance/cluster differentiation

### ğŸ” Performance Analysis
- **Slow Query Analysis**: Based on pg_stat_statements and CloudWatch logs
- **Performance Bottleneck Identification**: AI-powered optimization suggestions
- **Query History**: Execution pattern and performance trend analysis

### â˜ï¸ AWS Native Integration
- **Auto-discovery of RDS Instances/Clusters**
- **CloudWatch Log Stream Analysis**
- **Multi-AWS Account Support**
- **Secure Credential Management**

<div style="color: #666;">

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

### ğŸ¤– AI ê¸°ë°˜ ìì—°ì–´ SQL ë³€í™˜
- **ë‹¤ì¤‘ AI ëª¨ë¸ ì§€ì›**: OpenAI, Azure OpenAI, Google Gemini, Anthropic Claude
- **ë‹¤êµ­ì–´ ì§€ì›**: í•œêµ­ì–´ì™€ ì˜ì–´ ì¸í„°í˜ì´ìŠ¤ ë° ìë™ ì–¸ì–´ ê°ì§€
- **ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤**: ì±„íŒ… í˜•íƒœë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆì˜ì‘ë‹µ
- **ì¿¼ë¦¬ ì‹¤í–‰ ë° í•´ì„**: SQL ìë™ ì‹¤í–‰ ë° ê²°ê³¼ ë¶„ì„
- **ëŒ€í™” íˆìŠ¤í† ë¦¬**: ë°ì´í„°ë² ì´ìŠ¤ë³„ ëŒ€í™” ë‚´ì—­ ê´€ë¦¬

### ğŸ”— MCP (Model Context Protocol) í†µí•©
- **ìë™ ë°ì´í„°ë² ì´ìŠ¤ ë“±ë¡**: ë°ì´í„°ë² ì´ìŠ¤ ë“±ë¡ ì‹œ MCP ì„œë²„ ìë™ ì„¤ì •
- **ì‹¤ì‹œê°„ ë™ê¸°í™”**: ë“±ë¡ëœ ë°ì´í„°ë² ì´ìŠ¤ì™€ MCP ì„œë²„ ìë™ ë™ê¸°í™”
- **PostgreSQL MCP ì„œë²„**: ê° ë°ì´í„°ë² ì´ìŠ¤ë³„ ì „ìš© MCP ì„œë²„ ìƒì„±
- **AI ì±„íŒ… í†µí•©**: MCP ì»¨í…ìŠ¤íŠ¸ë¥¼ AI ì±„íŒ…ì— ìë™ í¬í•¨
- **ìƒíƒœ ëª¨ë‹ˆí„°ë§**: MCP ì—°ë™ ìƒíƒœ ì‹¤ì‹œê°„ í™•ì¸ ë° ê´€ë¦¬

### ğŸ“‹ ìë™í™” í”Œë ˆì´ë¶
- **ì‚¬ì „ ì •ì˜ëœ ì‹œë‚˜ë¦¬ì˜¤**: GDPR ì»´í”Œë¼ì´ì–¸ìŠ¤, ì¼ì¼ í—¬ìŠ¤ì²´í¬, ì£¼ê°„ ë¦¬ë·° ë“±
- **ìë™ ì‹¤í–‰ ëª¨ë“œ**: ë‹¨ê³„ë³„ ìë™ ì§„í–‰ (3ì´ˆ ê°„ê²©)
- **ìˆ˜ë™ ì‹¤í–‰ ëª¨ë“œ**: ë‹¨ê³„ë³„ ìˆ˜ë™ ì œì–´
- **ì‹¤ì‹œê°„ ì§„í–‰ë¥ **: í”Œë ˆì´ë¶ ì‹¤í–‰ ìƒíƒœ ì‹¤ì‹œê°„ í‘œì‹œ
- **ëŒ€í™” í†µí•©**: í”Œë ˆì´ë¶ ê²°ê³¼ë¥¼ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ì—ì„œ í™•ì¸

### ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- **AWS CloudWatch í†µí•©**: RDS/Aurora ë©”íŠ¸ë¦­ ì‹¤ì‹œê°„ ìˆ˜ì§‘
- **ì£¼ìš” ì§€í‘œ ëª¨ë‹ˆí„°ë§**: CPU, ë©”ëª¨ë¦¬, ì—°ê²° ìˆ˜, IOPS, ìŠ¤í† ë¦¬ì§€ ë“±
- **ì‹œê°í™”**: ì¹´ë“œ + ê·¸ë˜í”„ í˜•íƒœì˜ ì§ê´€ì ì¸ ëŒ€ì‹œë³´ë“œ
- **ìë™ íŒë³„**: ì¸ìŠ¤í„´ìŠ¤/í´ëŸ¬ìŠ¤í„° ìë™ êµ¬ë¶„

### ğŸ” ì„±ëŠ¥ ë¶„ì„
- **ìŠ¬ë¡œìš° ì¿¼ë¦¬ ë¶„ì„**: pg_stat_statements ë° CloudWatch ë¡œê·¸ ê¸°ë°˜
- **ì„±ëŠ¥ ë³‘ëª© ì‹ë³„**: AI ê¸°ë°˜ ìµœì í™” ì œì•ˆ
- **ì¿¼ë¦¬ íˆìŠ¤í† ë¦¬**: ì‹¤í–‰ íŒ¨í„´ ë° ì„±ëŠ¥ ì¶”ì´ ë¶„ì„

### â˜ï¸ AWS ë„¤ì´í‹°ë¸Œ í†µí•©
- **RDS ì¸ìŠ¤í„´ìŠ¤/í´ëŸ¬ìŠ¤í„° ìë™ ë°œê²¬**
- **CloudWatch ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ ë¶„ì„**
- **ë‹¤ì¤‘ AWS ê³„ì • ì§€ì›**
- **ì•ˆì „í•œ ìê²©ì¦ëª… ê´€ë¦¬**

</div>

## ğŸ“– ì‚¬ìš© ê°€ì´ë“œ / User Guide

### 1. ë°ì´í„°ë² ì´ìŠ¤ ë“±ë¡ / Database Registration

1. **DB ê´€ë¦¬** ë©”ë‰´ì—ì„œ ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ì¶”ê°€
2. **CloudWatch ID** ì…ë ¥ (AWS RDS ì¸ìŠ¤í„´ìŠ¤/í´ëŸ¬ìŠ¤í„° IDì™€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨)
3. ì—°ê²° í…ŒìŠ¤íŠ¸ í›„ ì €ì¥

**English:**
1. Add a new database from the **DB Management** menu
2. Enter **CloudWatch ID** (must exactly match AWS RDS instance/cluster ID)
3. Test connection and save

### 2. AI ëª¨ë¸ ì„¤ì • / AI Model Configuration

1. **AI ë“±ë¡** ë©”ë‰´ì—ì„œ ì‚¬ìš©í•  AI ëª¨ë¸ ì„ íƒ
2. API í‚¤ ì…ë ¥ ë° ëª¨ë¸ ì„¤ì •
3. ì›í•˜ëŠ” ëª¨ë¸ì„ í™œì„±í™”

**English:**
1. Select AI model to use from **AI Registration** menu
2. Enter API key and configure model settings
3. Activate desired model

### 3. CloudWatch ëª¨ë‹ˆí„°ë§ / CloudWatch Monitoring

1. **ëª¨ë‹ˆí„°ë§** ë©”ë‰´ì—ì„œ ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒ
2. ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ í™•ì¸
3. ê¸°ê°„/ì£¼ê¸° ì¡°ì •í•˜ì—¬ ìƒì„¸ ë¶„ì„

**English:**
1. Select target database from **Monitoring** menu
2. Check real-time metrics
3. Adjust time period/interval for detailed analysis

### 4. AI ì±„íŒ… ì‚¬ìš© / Using AI Chat

```
ì‚¬ìš©ì: "í˜„ì¬ DB ìƒíƒœ ì–´ë•Œ?"
AI: í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤...

ì‚¬ìš©ì: "ëŠë¦° ì¿¼ë¦¬ ì°¾ì•„ì¤˜"
AI: ì‹¤í–‰ ì‹œê°„ì´ ê¸´ ì¿¼ë¦¬ë“¤ì„ ì¡°íšŒí•˜ê² ìŠµë‹ˆë‹¤...
```

**English:**
```
User: "How is the current DB status?"
AI: I'll check the current database status for you...

User: "Find slow queries"
AI: I'll query for long-running queries...
```

### 5. MCP ì„¤ì • ë° ì‚¬ìš© / MCP Setup and Usage

#### MCP ì´ˆê¸° ì„¤ì • / MCP Initial Setup
```bash
# uv ë° uvx ì„¤ì¹˜ (MCP ì„œë²„ ì‹¤í–‰ì— í•„ìš”)
curl -LsSf https://astral.sh/uv/install.sh | sh

# ë˜ëŠ” Homebrew ì‚¬ìš© (macOS)
brew install uv
```

**English:**
```bash
# Install uv and uvx (required for MCP server execution)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Or use Homebrew (macOS)
brew install uv
```

#### MCP ì„¤ì • íŒŒì¼ ìœ„ì¹˜ (ìš°ì„ ìˆœìœ„ë³„) / MCP Configuration File Locations (by Priority)

AI DBAgentëŠ” ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ MCP ì„¤ì • íŒŒì¼ ìœ„ì¹˜ë¥¼ ìœ ì—°í•˜ê²Œ ì§€ì›í•©ë‹ˆë‹¤:

**English:** AI DBAgent flexibly supports MCP configuration file locations for use in various environments:

1. **í™˜ê²½ë³€ìˆ˜ë¡œ ì§ì ‘ ì§€ì •** (ìµœìš°ì„ ) / **Direct Environment Variable** (Highest Priority)
   ```bash
   export MCP_CONFIG_PATH="/path/to/your/mcp.json"
   ```

2. **í”„ë¡œì íŠ¸ config í´ë”** (ê¶Œì¥) / **Project Config Folder** (Recommended)
   ```bash
   # config/mcp.json íŒŒì¼ ìƒì„±
   cp config/mcp.example.json config/mcp.json
   # ì„¤ì • ìˆ˜ì • í›„ ì‚¬ìš©
   ```
   **English:**
   ```bash
   # Create config/mcp.json file
   cp config/mcp.example.json config/mcp.json
   # Modify settings and use
   ```

3. **Kiro IDE ì‚¬ìš©ììš©** / **For Kiro IDE Users**
   ```bash
   # .kiro/settings/mcp.json (Kiro IDE ìë™ ìƒì„±)
   # .kiro/settings/mcp.json (Auto-generated by Kiro IDE)
   ```

4. **ê¸°íƒ€ ì¼ë°˜ì ì¸ ìœ„ì¹˜ë“¤** / **Other Common Locations**
   ```
   mcp/mcp.json
   settings/mcp.json
   .config/mcp.json
   mcp.json (í”„ë¡œì íŠ¸ ë£¨íŠ¸ / project root)
   ```

#### MCP ì„¤ì • íŒŒì¼ ì˜ˆì‹œ

```json
{
  "mcpServers": {
    "postgres_mydb": {
      "command": "uvx",
      "args": ["mcp-server-postgres@latest"],
      "env": {
        "POSTGRES_CONNECTION_STRING": "postgresql://user:pass@host:5432/db"
      },
      "disabled": false,
      "autoApprove": ["query", "list_tables", "describe_table"]
    },
    "cloudwatch_logs_mydb": {
      "command": "python3",
      "args": ["scripts/aws_cloudwatch_mcp_server.py"],
      "env": {
        "AWS_DEFAULT_REGION": "ap-northeast-2",
        "RDS_INSTANCE_ID": "my-rds-instance"
      },
      "disabled": false,
      "autoApprove": ["get_slow_logs", "get_error_logs", "search_logs"]
    }
  }
}
```

#### MCP ê¸°ëŠ¥ ì‚¬ìš© / Using MCP Features
1. **ìë™ ë™ê¸°í™”**: ë°ì´í„°ë² ì´ìŠ¤ ë“±ë¡ ì‹œ MCP ì„œë²„ê°€ ìë™ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤
2. **ìƒíƒœ í™•ì¸**: ëŒ€ì‹œë³´ë“œì—ì„œ MCP ì—°ë™ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸
3. **ìˆ˜ë™ ë™ê¸°í™”**: í•„ìš” ì‹œ "ë™ê¸°í™”" ë²„íŠ¼ìœ¼ë¡œ ìˆ˜ë™ ë™ê¸°í™” ì‹¤í–‰
4. **AI ì±„íŒ…**: MCP ì»¨í…ìŠ¤íŠ¸ê°€ ìë™ìœ¼ë¡œ AI ì±„íŒ…ì— í¬í•¨ë˜ì–´ ë” ì •í™•í•œ ì‘ë‹µ ì œê³µ

**English:**
1. **Auto Sync**: MCP servers are automatically configured when registering databases
2. **Status Check**: Real-time monitoring of MCP integration status on dashboard
3. **Manual Sync**: Execute manual sync with "Sync" button when needed
4. **AI Chat**: MCP context automatically included in AI chat for more accurate responses

#### MCP í…ŒìŠ¤íŠ¸ / MCP Testing
```bash
# MCP ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
python scripts/test_mcp.py

# MCP ë™ê¸°í™” í…ŒìŠ¤íŠ¸
python scripts/test_mcp.py sync

# íŠ¹ì • ì„¤ì • íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸
MCP_CONFIG_PATH="config/mcp.json" python scripts/test_mcp.py
```

**English:**
```bash
# Test MCP functionality
python scripts/test_mcp.py

# Test MCP synchronization
python scripts/test_mcp.py sync

# Test with specific config file
MCP_CONFIG_PATH="config/mcp.json" python scripts/test_mcp.py
```

#### íŒ€ í˜‘ì—…ì„ ìœ„í•œ MCP ì„¤ì • / MCP Setup for Team Collaboration

**Gitì— í¬í•¨í•  íŒŒì¼ë“¤:** / **Files to Include in Git:**
- `config/mcp.example.json` - ì˜ˆì‹œ ì„¤ì • (ë¯¼ê°ì •ë³´ ì œì™¸) / Example config (excluding sensitive info)
- `scripts/aws_cloudwatch_mcp_server.py` - CloudWatch MCP ì„œë²„ / CloudWatch MCP server
- `scripts/postgres_mcp_server.py` - PostgreSQL MCP ì„œë²„ / PostgreSQL MCP server

**Gitì—ì„œ ì œì™¸í•  íŒŒì¼ë“¤ (.gitignore):** / **Files to Exclude from Git (.gitignore):**
```gitignore
# MCP ì„¤ì • íŒŒì¼ë“¤ (ë¯¼ê°ì •ë³´ í¬í•¨) / MCP config files (containing sensitive info)
config/mcp.json
.kiro/settings/mcp.json
mcp.json

# AWS ìê²©ì¦ëª… / AWS credentials
.env
.env.local
```

**íŒ€ì› ì„¤ì • ê°€ì´ë“œ:** / **Team Member Setup Guide:**
```bash
# 1. ì˜ˆì‹œ íŒŒì¼ ë³µì‚¬ / Copy example file
cp config/mcp.example.json config/mcp.json

# 2. ê°œì¸ ì„¤ì • ìˆ˜ì • / Modify personal settings
# - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´ / Database connection info
# - AWS ìê²©ì¦ëª… / AWS credentials
# - RDS ì¸ìŠ¤í„´ìŠ¤ ID ë“± / RDS instance ID, etc.

# 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ì„ íƒì‚¬í•­) / Set environment variables (optional)
export MCP_CONFIG_PATH="config/mcp.json"
```

### 6. í”Œë ˆì´ë¶ ì‹¤í–‰ / Playbook Execution

1. **í”Œë ˆì´ë¶** ë©”ë‰´ì—ì„œ ì›í•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ
2. ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒ
3. **ì‹¤í–‰** ë²„íŠ¼ í´ë¦­
4. ìë™ìœ¼ë¡œ ì±„íŒ… í˜ì´ì§€ë¡œ ì´ë™í•˜ì—¬ í”Œë ˆì´ë¶ ì‹¤í–‰
5. ìë™ ëª¨ë“œì—ì„œ ê° ë‹¨ê³„ê°€ 3ì´ˆ ê°„ê²©ìœ¼ë¡œ ìˆœì°¨ ì‹¤í–‰

**English:**
1. Select desired scenario from **Playbooks** menu
2. Select target database
3. Click **Execute** button
4. Automatically navigate to chat page for playbook execution
5. In auto mode, each step executes sequentially at 3-second intervals

#### ì‚¬ìš© ê°€ëŠ¥í•œ í”Œë ˆì´ë¶ / Available Playbooks
- **GDPR ì»´í”Œë¼ì´ì–¸ìŠ¤**: ê°œì¸ì •ë³´ ê´€ë ¨ ë°ì´í„° í˜„í™© ì ê²€ / **GDPR Compliance**: Personal data status inspection
- **ì¼ì¼ í—¬ìŠ¤ì²´í¬**: ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ë° ì„±ëŠ¥ ì ê²€ / **Daily Health Check**: Database status and performance inspection
- **ì£¼ê°„ ë¦¬ë·°**: ì£¼ê°„ ì„±ëŠ¥ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„± / **Weekly Review**: Weekly performance analysis and report generation
- **ë³´ì•ˆ ê°ì‚¬**: ë³´ì•ˆ ì„¤ì • ë° ê¶Œí•œ ì ê²€ / **Security Audit**: Security settings and permission inspection
- **ìš©ëŸ‰ ë¶„ì„**: ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©ëŸ‰ ë° ì¦ê°€ ì¶”ì´ ë¶„ì„ / **Capacity Analysis**: Storage usage and growth trend analysis

## ğŸ”§ ê³ ê¸‰ ì„¤ì • / Advanced Configuration

### CloudWatch ì„¤ì • / CloudWatch Configuration

```bash
# AWS CLI ì„¤ì •
aws configure

# ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export AWS_ACCESS_KEY_ID=your_access_key
export AWS_SECRET_ACCESS_KEY=your_secret_key
export AWS_DEFAULT_REGION=ap-northeast-2
```

**English:**
```bash
# AWS CLI configuration
aws configure

# Or set environment variables
export AWS_ACCESS_KEY_ID=your_access_key
export AWS_SECRET_ACCESS_KEY=your_secret_key
export AWS_DEFAULT_REGION=ap-northeast-2
```

### í”Œë ˆì´ë¶ ì»¤ìŠ¤í„°ë§ˆì´ì§• / Playbook Customization

`playbooks.json` íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ ìë™í™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

**English:** You can add automation scenarios by modifying the `playbooks.json` file:

```json
{
  "name": "customMonitoring",
  "description": "ì»¤ìŠ¤í…€ ëª¨ë‹ˆí„°ë§ í”Œë ˆì´ë¶",
  "steps": [
    {
      "title": "CPU ì‚¬ìš©ë¥  í™•ì¸",
      "prompt": "í˜„ì¬ CPU ì‚¬ìš©ë¥ ì´ 80% ì´ìƒì¸ê°€ìš”?"
    }
  ]
}
```

**English Example:**
```json
{
  "name": "customMonitoring",
  "description": "Custom monitoring playbook",
  "steps": [
    {
      "title": "Check CPU Usage",
      "prompt": "Is the current CPU usage above 80%?"
    }
  ]
}
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ / Testing

```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/

# íŠ¹ì • í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/test_database.py

# ì»¤ë²„ë¦¬ì§€ í¬í•¨ í…ŒìŠ¤íŠ¸
pytest --cov=backend tests/
```

**English:**
```bash
# Run unit tests
pytest tests/

# Run specific tests
pytest tests/test_database.py

# Run tests with coverage
pytest --cov=backend tests/
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° / Project Structure

```
AI_DBAgent/
â”œâ”€â”€ backend/              # FastAPI ë°±ì—”ë“œ / FastAPI Backend
â”‚   â”œâ”€â”€ api/             # API ë¼ìš°í„° / API Routers
â”‚   â”œâ”€â”€ integrations/    # AWS í†µí•© / AWS Integrations
â”‚   â”œâ”€â”€ models/          # ë°ì´í„° ëª¨ë¸ / Data Models
â”‚   â”œâ”€â”€ monitoring/      # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° / Metric Collectors
â”‚   â””â”€â”€ services/        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ / Business Logic
â”œâ”€â”€ frontend/            # React í”„ë¡ íŠ¸ì—”ë“œ / React Frontend
â”‚   â”œâ”€â”€ src/            # ì†ŒìŠ¤ ì½”ë“œ / Source Code
â”‚   â””â”€â”€ public/         # ì •ì  íŒŒì¼ / Static Files
â”œâ”€â”€ agent/              # ë°±ê·¸ë¼ìš´ë“œ ì—ì´ì „íŠ¸ / Background Agent
â”œâ”€â”€ database/           # DB ìŠ¤í‚¤ë§ˆ / DB Schema
â”œâ”€â”€ docker/             # Docker ì„¤ì • / Docker Configuration
â”œâ”€â”€ scripts/            # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸ / Utility Scripts
â”œâ”€â”€ tests/              # í…ŒìŠ¤íŠ¸ ì½”ë“œ / Test Code
â””â”€â”€ templates/          # HTML í…œí”Œë¦¿ / HTML Templates
```

## ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ… / Troubleshooting

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ / Common Issues

**Q: CloudWatch ë°ì´í„°ê°€ í‘œì‹œë˜ì§€ ì•Šì•„ìš”** / **Q: CloudWatch data is not displayed**
- AWS ìê²©ì¦ëª…ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸ / Check if AWS credentials are correct
- CloudWatch IDê°€ AWS ì½˜ì†”ì˜ ì¸ìŠ¤í„´ìŠ¤/í´ëŸ¬ìŠ¤í„° IDì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸ / Verify CloudWatch ID exactly matches AWS console instance/cluster ID
- í•´ë‹¹ ë¦¬ì „ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸ / Check if data exists in the region

**Q: AI ì‘ë‹µì´ ì—†ì–´ìš”** / **Q: No AI response**
- AI ëª¨ë¸ì´ ì„ íƒë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ / Check if AI model is selected
- API í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸ / Verify API key is valid
- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸ / Check network connection status

**Q: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì•ˆ ë¼ìš”** / **Q: Database connection failed**
- ì—°ê²° ì •ë³´ (í˜¸ìŠ¤íŠ¸, í¬íŠ¸, ì‚¬ìš©ìëª…, ë¹„ë°€ë²ˆí˜¸) í™•ì¸ / Check connection info (host, port, username, password)
- ë°©í™”ë²½ ì„¤ì • í™•ì¸ / Check firewall settings
- ë°ì´í„°ë² ì´ìŠ¤ ì„œë²„ ìƒíƒœ í™•ì¸ / Check database server status

### ë¡œê·¸ í™•ì¸ / Log Checking

```bash
# ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸
tail -f logs/app.log

# ì—ëŸ¬ ë¡œê·¸
tail -f logs/error.log

# Docker ë¡œê·¸
docker-compose logs -f app
```

**English:**
```bash
# Application logs
tail -f logs/app.log

# Error logs
tail -f logs/error.log

# Docker logs
docker-compose logs -f app
```

## ğŸ¤ ê¸°ì—¬í•˜ê¸° / Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

**í•œêµ­ì–´:**
1. ì €ì¥ì†Œë¥¼ í¬í¬í•˜ì„¸ìš”
2. ê¸°ëŠ¥ ë¸Œëœì¹˜ë¥¼ ìƒì„±í•˜ì„¸ìš” (`git checkout -b feature/amazing-feature`)
3. ë³€ê²½ì‚¬í•­ì„ ì»¤ë°‹í•˜ì„¸ìš” (`git commit -m 'Add some amazing feature'`)
4. ë¸Œëœì¹˜ì— í‘¸ì‹œí•˜ì„¸ìš” (`git push origin feature/amazing-feature`)
5. Pull Requestë¥¼ ì—´ì–´ì£¼ì„¸ìš”

## ğŸ“„ ë¼ì´ì„ ìŠ¤ / License

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

**English:** This project is distributed under the MIT License. See the `LICENSE` file for more details.

## ğŸ™‹â€â™‚ï¸ ì§€ì› / Support

- **ì´ìŠˆ ë¦¬í¬íŠ¸**: GitHub Issues / **Issue Reports**: GitHub Issues
- **ê¸°ëŠ¥ ìš”ì²­**: GitHub Discussions / **Feature Requests**: GitHub Discussions
- **ë¬¸ì„œ**: í”„ë¡œì íŠ¸ Wiki / **Documentation**: Project Wiki

---

**Made with â¤ï¸ for SRE/DBA Engineers**